{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veritaem/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/Copy_of_LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ryp-TVm4njD",
        "colab_type": "text"
      },
      "source": [
        "# Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvG3hGc8d2iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7e2dc947-d9c9-43e3-806a-9bae6c1d4a53"
      },
      "source": [
        "!pip install -U nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNJ-tOBs4jM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48ec8365-1290-48bf-8ee9-f51978ccf227"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycgEh89Kd8qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "a96ef968-afa3-4694-d3c2-fe4c8a84ad48"
      },
      "source": [
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn(1).csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen  ... MonthlyCharges TotalCharges  Churn\n",
              "0  7590-VHVEG  Female              0  ...          29.85        29.85     No\n",
              "1  5575-GNVDE    Male              0  ...          56.95       1889.5     No\n",
              "2  3668-QPYBK    Male              0  ...          53.85       108.15    Yes\n",
              "3  7795-CFOCW    Male              0  ...          42.30      1840.75     No\n",
              "4  9237-HQITU  Female              0  ...          70.70       151.65    Yes\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHhXkGggePrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = StandardScaler()\n",
        "oe = OrdinalEncoder()\n",
        "df = df.drop('customerID', axis=1)\n",
        "df['Churn'] = df.Churn.replace({'Yes':0, 'No':1})\n",
        "\n",
        "X = df.drop('Churn', axis = 1).values\n",
        "y = df.Churn.values\n",
        "\n",
        "X = oe.fit_transform(X).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8-o9AHDlamm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwrfGCCvhR_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "\n",
        "inputs = X.shape[1]\n",
        "epochs = 30\n",
        "batch_size = 10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                          test_size=0.2,\n",
        "                          random_state=seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nq6pkPMiJv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx93wPG6h8dN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6bb119a-c5e5-46b8-8cdd-a01441dd0796"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation = 'relu', input_shape=(inputs,)))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "          \n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0625 01:48:36.893865 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0625 01:48:36.912370 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0625 01:48:36.915588 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0625 01:48:36.974593 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0625 01:48:37.000931 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0625 01:48:37.008671 140696253265792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0625 01:48:37.192473 140696253265792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 5634 samples, validate on 1409 samples\n",
            "Epoch 1/30\n",
            "5634/5634 [==============================] - 1s 218us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 2/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 3/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 4/30\n",
            "5634/5634 [==============================] - 1s 158us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 5/30\n",
            "5634/5634 [==============================] - 1s 158us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 6/30\n",
            "5634/5634 [==============================] - 1s 159us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 7/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 8/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 9/30\n",
            "5634/5634 [==============================] - 1s 161us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 10/30\n",
            "5634/5634 [==============================] - 1s 159us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 11/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 12/30\n",
            "5634/5634 [==============================] - 1s 162us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 13/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 14/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 15/30\n",
            "5634/5634 [==============================] - 1s 155us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 16/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 17/30\n",
            "5634/5634 [==============================] - 1s 158us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 18/30\n",
            "5634/5634 [==============================] - 1s 159us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 19/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 20/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 21/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 22/30\n",
            "5634/5634 [==============================] - 1s 157us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 23/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 24/30\n",
            "5634/5634 [==============================] - 1s 162us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 25/30\n",
            "5634/5634 [==============================] - 1s 162us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 26/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 27/30\n",
            "5634/5634 [==============================] - 1s 155us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 28/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 29/30\n",
            "5634/5634 [==============================] - 1s 160us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n",
            "Epoch 30/30\n",
            "5634/5634 [==============================] - 1s 162us/step - loss: 4.2247 - acc: 0.7350 - val_loss: 4.2543 - val_acc: 0.7331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff624cdb0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ6t9ZwYrxoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmv4m0UCre1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56f993c3-8b09-4ad2-ab98-73facebd873b"
      },
      "source": [
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=inputs, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs = 30, batch_size = 8, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2]\n",
        "momentum = [0.0, 0.2, 0.4]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "'''param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
        "              'epochs': [20]}'''\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 1.1798 - acc: 0.2675\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 133us/step - loss: 0.6943 - acc: 0.5376\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 134us/step - loss: 0.6022 - acc: 0.7274\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 134us/step - loss: 0.5829 - acc: 0.7306\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 134us/step - loss: 0.5793 - acc: 0.7323\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 134us/step - loss: 0.5780 - acc: 0.7325\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 134us/step - loss: 0.5775 - acc: 0.7325\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 132us/step - loss: 0.5772 - acc: 0.7308\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 137us/step - loss: 0.5764 - acc: 0.7323\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5758 - acc: 0.7325\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5750 - acc: 0.7340\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5746 - acc: 0.7340\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5747 - acc: 0.7335\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5749 - acc: 0.7331\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5745 - acc: 0.7338\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5745 - acc: 0.7338\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5737 - acc: 0.7340\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5730 - acc: 0.7338\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5841 - acc: 0.7329\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5790 - acc: 0.7329\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5770 - acc: 0.7331\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5766 - acc: 0.7331\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5761 - acc: 0.7331\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5761 - acc: 0.7331\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5759 - acc: 0.7331\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5760 - acc: 0.7331\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5757 - acc: 0.7331\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5751 - acc: 0.7331\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5753 - acc: 0.7331\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5752 - acc: 0.7331\n",
            "2348/2348 [==============================] - 0s 100us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 189us/step - loss: 0.5947 - acc: 0.7323\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5809 - acc: 0.7325\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5804 - acc: 0.7318\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5789 - acc: 0.7325\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5780 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5767 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 136us/step - loss: 0.5770 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5760 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5743 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5777 - acc: 0.7325\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5744 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 137us/step - loss: 0.5739 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5726 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5721 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5718 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5719 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5726 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5724 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5716 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5730 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5735 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5727 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5734 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5729 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5764 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5743 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5726 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5717 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5738 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 136us/step - loss: 0.5700 - acc: 0.7327\n",
            "2348/2348 [==============================] - 0s 96us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 1s 195us/step - loss: 0.5949 - acc: 0.7264\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 137us/step - loss: 0.5713 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 138us/step - loss: 0.5667 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 137us/step - loss: 0.5664 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5661 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5659 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 136us/step - loss: 0.5660 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5666 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5652 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 138us/step - loss: 0.5647 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5666 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 137us/step - loss: 0.5605 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5665 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5764 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5762 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5721 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5676 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5610 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 135us/step - loss: 0.5685 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5654 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5638 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5658 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5640 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 138us/step - loss: 0.5627 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5616 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5631 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5634 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 139us/step - loss: 0.5659 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5635 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 137us/step - loss: 0.5619 - acc: 0.7379\n",
            "2347/2347 [==============================] - 0s 110us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 203us/step - loss: 0.6147 - acc: 0.6873\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5783 - acc: 0.7333\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5810 - acc: 0.7331\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5809 - acc: 0.7335\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5777 - acc: 0.7333\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5773 - acc: 0.7333\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 137us/step - loss: 0.5748 - acc: 0.7333\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5691 - acc: 0.7325\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5704 - acc: 0.7329\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5737 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5735 - acc: 0.7333\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5741 - acc: 0.7333\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5723 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 137us/step - loss: 0.5697 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5727 - acc: 0.7335\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5731 - acc: 0.7340\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5724 - acc: 0.7348\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5719 - acc: 0.7340\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5696 - acc: 0.7340\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 137us/step - loss: 0.5697 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5684 - acc: 0.7340\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5681 - acc: 0.7342\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5715 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5705 - acc: 0.7348\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5666 - acc: 0.7329\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5702 - acc: 0.7346\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5713 - acc: 0.7338\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5730 - acc: 0.7338\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5701 - acc: 0.7308\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5703 - acc: 0.7338\n",
            "2348/2348 [==============================] - 0s 118us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 211us/step - loss: 0.6542 - acc: 0.6609\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5872 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5775 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5744 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5763 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 136us/step - loss: 0.5770 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5743 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5727 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5733 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5717 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5705 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5712 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5693 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5706 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5708 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5713 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5714 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5698 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5695 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5693 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5711 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5688 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5731 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5768 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5719 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5705 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5686 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5685 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5672 - acc: 0.7327\n",
            "2348/2348 [==============================] - 0s 123us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 1s 222us/step - loss: 0.6140 - acc: 0.7181\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 141us/step - loss: 0.5717 - acc: 0.7372\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5665 - acc: 0.7374\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 143us/step - loss: 0.5660 - acc: 0.7376\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5661 - acc: 0.7374\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5646 - acc: 0.7374\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 141us/step - loss: 0.5626 - acc: 0.7394\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5621 - acc: 0.7374\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5637 - acc: 0.7387\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5651 - acc: 0.7387\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 138us/step - loss: 0.5645 - acc: 0.7389\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5639 - acc: 0.7387\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5659 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5629 - acc: 0.7387\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5651 - acc: 0.7366\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5638 - acc: 0.7376\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5628 - acc: 0.7376\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5640 - acc: 0.7376\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5628 - acc: 0.7376\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 143us/step - loss: 0.5614 - acc: 0.7376\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5633 - acc: 0.7376\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5630 - acc: 0.7376\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 143us/step - loss: 0.5634 - acc: 0.7376\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5628 - acc: 0.7376\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5639 - acc: 0.7376\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5612 - acc: 0.7376\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5616 - acc: 0.7376\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5676 - acc: 0.7376\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 138us/step - loss: 0.5701 - acc: 0.7376\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 140us/step - loss: 0.5680 - acc: 0.7379\n",
            "2347/2347 [==============================] - 0s 134us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 236us/step - loss: 0.6143 - acc: 0.7216\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5782 - acc: 0.7306\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5723 - acc: 0.7304\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5721 - acc: 0.7314\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5715 - acc: 0.7321\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5725 - acc: 0.7338\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5718 - acc: 0.7338\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5704 - acc: 0.7338\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5702 - acc: 0.7338\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5700 - acc: 0.7338\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5693 - acc: 0.7338\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5744 - acc: 0.7338\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5735 - acc: 0.7335\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5717 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5699 - acc: 0.7342\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5701 - acc: 0.7340\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5697 - acc: 0.7342\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5732 - acc: 0.7342\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5719 - acc: 0.7338\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5698 - acc: 0.7342\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5704 - acc: 0.7338\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5795 - acc: 0.7344\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5770 - acc: 0.7363\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5763 - acc: 0.7370\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5763 - acc: 0.7361\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5762 - acc: 0.7359\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5761 - acc: 0.7370\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5761 - acc: 0.7372\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5760 - acc: 0.7370\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5762 - acc: 0.7363\n",
            "2348/2348 [==============================] - 0s 141us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 244us/step - loss: 0.6583 - acc: 0.6232\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5883 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5851 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.6059 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5864 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5882 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5845 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5825 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5816 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5801 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5766 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5792 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5786 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5743 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5715 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5710 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5714 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5706 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5714 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5702 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5704 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5700 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5699 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5720 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5696 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 142us/step - loss: 0.5709 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 138us/step - loss: 0.5703 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 141us/step - loss: 0.5696 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5700 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 139us/step - loss: 0.5711 - acc: 0.7327\n",
            "2348/2348 [==============================] - 0s 140us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 1s 244us/step - loss: 0.5739 - acc: 0.7379\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5718 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 143us/step - loss: 0.5721 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5702 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5694 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5689 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5687 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5684 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5679 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5679 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5677 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5672 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5677 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5670 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5691 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5685 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5667 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5665 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5650 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5727 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5721 - acc: 0.7376\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 142us/step - loss: 0.5716 - acc: 0.7376\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5717 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5715 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 143us/step - loss: 0.5711 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5713 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5692 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5676 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5667 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 145us/step - loss: 0.5669 - acc: 0.7379\n",
            "2347/2347 [==============================] - 0s 160us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 262us/step - loss: 0.6120 - acc: 0.7048\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5828 - acc: 0.7333\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5798 - acc: 0.7333\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5800 - acc: 0.7333\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5789 - acc: 0.7333\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5770 - acc: 0.7333\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5771 - acc: 0.7333\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5752 - acc: 0.7333\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5744 - acc: 0.7333\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5755 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5736 - acc: 0.7333\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5780 - acc: 0.7333\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5755 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5745 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5749 - acc: 0.7333\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5752 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5760 - acc: 0.7333\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5749 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5739 - acc: 0.7333\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5786 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5757 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5760 - acc: 0.7333\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5738 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 140us/step - loss: 0.5754 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5748 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5740 - acc: 0.7333\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5727 - acc: 0.7333\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5740 - acc: 0.7331\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5715 - acc: 0.7331\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 143us/step - loss: 0.5738 - acc: 0.7318\n",
            "2348/2348 [==============================] - 0s 164us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 276us/step - loss: 0.5816 - acc: 0.7306\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5759 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5736 - acc: 0.7335\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5712 - acc: 0.7325\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5729 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5751 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5752 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5714 - acc: 0.7325\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5733 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5728 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5740 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5764 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5764 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5763 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5736 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5731 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5761 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5774 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5773 - acc: 0.7325\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5773 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5761 - acc: 0.7329\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5745 - acc: 0.7316\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5768 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5751 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5725 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5752 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5771 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5767 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5767 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5776 - acc: 0.7327\n",
            "2348/2348 [==============================] - 0s 177us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 1s 275us/step - loss: 0.5743 - acc: 0.7379\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5728 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5735 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5734 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5745 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5758 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5706 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5697 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5693 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5710 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5751 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5749 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5745 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5744 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5738 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5738 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5721 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5717 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5710 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5699 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 144us/step - loss: 0.5708 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5701 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5654 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5692 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5706 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5724 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5741 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5756 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5753 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5756 - acc: 0.7379\n",
            "2347/2347 [==============================] - 0s 184us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 288us/step - loss: 0.5915 - acc: 0.7314\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5846 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5832 - acc: 0.7329\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5814 - acc: 0.7329\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5810 - acc: 0.7329\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5809 - acc: 0.7329\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5799 - acc: 0.7329\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5788 - acc: 0.7331\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5751 - acc: 0.7331\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5763 - acc: 0.7331\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5759 - acc: 0.7331\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5766 - acc: 0.7331\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5772 - acc: 0.7331\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5764 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5756 - acc: 0.7333\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5740 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5769 - acc: 0.7333\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5775 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5780 - acc: 0.7333\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5776 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5776 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5776 - acc: 0.7333\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5768 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5766 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 144us/step - loss: 0.5771 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5768 - acc: 0.7333\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5765 - acc: 0.7333\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 145us/step - loss: 0.5768 - acc: 0.7333\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5766 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5773 - acc: 0.7333\n",
            "2348/2348 [==============================] - 0s 189us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 1s 303us/step - loss: 0.5774 - acc: 0.7289\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5761 - acc: 0.7318\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5784 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5816 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5812 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5811 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5812 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5810 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5813 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5811 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5812 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5813 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5811 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5813 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5809 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5808 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5816 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5811 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5807 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 146us/step - loss: 0.5810 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5807 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5814 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5812 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5812 - acc: 0.7327\n",
            "2348/2348 [==============================] - 0s 197us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 1s 306us/step - loss: 0.5910 - acc: 0.7213\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 146us/step - loss: 0.5735 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5718 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5710 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 147us/step - loss: 0.5678 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5654 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5677 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5708 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 152us/step - loss: 0.5724 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5730 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5731 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5722 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5699 - acc: 0.7381\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5669 - acc: 0.7359\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5699 - acc: 0.7359\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5676 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5674 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5711 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5732 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5726 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5726 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5691 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5668 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5694 - acc: 0.7381\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5692 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5703 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5670 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5671 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 148us/step - loss: 0.5696 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 149us/step - loss: 0.5683 - acc: 0.7379\n",
            "2347/2347 [==============================] - 0s 209us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 326us/step - loss: 0.5889 - acc: 0.7210\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5797 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5794 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5806 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5796 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5792 - acc: 0.7329\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5783 - acc: 0.7329\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5781 - acc: 0.7329\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5776 - acc: 0.7329\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5775 - acc: 0.7329\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5752 - acc: 0.7329\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5759 - acc: 0.7329\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5761 - acc: 0.7331\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5737 - acc: 0.7331\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5774 - acc: 0.7331\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5723 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5730 - acc: 0.7333\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5736 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5790 - acc: 0.7333\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 148us/step - loss: 0.5785 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5768 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5752 - acc: 0.7333\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5765 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5757 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5768 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5759 - acc: 0.7340\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5767 - acc: 0.7331\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5771 - acc: 0.7333\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5754 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 147us/step - loss: 0.5731 - acc: 0.7333\n",
            "2348/2348 [==============================] - 1s 214us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 337us/step - loss: 0.5954 - acc: 0.7180\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5812 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5782 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5749 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5749 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5752 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5775 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5777 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5775 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5720 - acc: 0.7321\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5732 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5734 - acc: 0.7314\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5722 - acc: 0.7323\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5725 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5716 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5719 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5713 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5754 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 149us/step - loss: 0.5748 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5780 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5739 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5746 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 150us/step - loss: 0.5767 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5748 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5760 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5744 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5732 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5717 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5733 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5768 - acc: 0.7327\n",
            "2348/2348 [==============================] - 1s 232us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 333us/step - loss: 0.5891 - acc: 0.7166\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5774 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5764 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5758 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5752 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5717 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5694 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5697 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5645 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5708 - acc: 0.7374\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 152us/step - loss: 0.5710 - acc: 0.7398\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5725 - acc: 0.7368\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5719 - acc: 0.7376\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5728 - acc: 0.7357\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5690 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5723 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5756 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 152us/step - loss: 0.5761 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5754 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5754 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5757 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5755 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5756 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5753 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5755 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5755 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5757 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5756 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5751 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5754 - acc: 0.7379\n",
            "2347/2347 [==============================] - 1s 237us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 362us/step - loss: 0.5838 - acc: 0.7333\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5834 - acc: 0.7333\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5851 - acc: 0.7333\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5834 - acc: 0.7333\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5857 - acc: 0.7333\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5837 - acc: 0.7333\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5842 - acc: 0.7333\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5842 - acc: 0.7333\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5849 - acc: 0.7333\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5844 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5834 - acc: 0.7333\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5850 - acc: 0.7333\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5843 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5839 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5855 - acc: 0.7333\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5846 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5824 - acc: 0.7333\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5842 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5851 - acc: 0.7333\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5825 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5855 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5840 - acc: 0.7333\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5846 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5839 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5848 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5851 - acc: 0.7333\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5845 - acc: 0.7333\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5838 - acc: 0.7333\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5830 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5850 - acc: 0.7333\n",
            "2348/2348 [==============================] - 1s 246us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 359us/step - loss: 0.5854 - acc: 0.7272\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5833 - acc: 0.7327\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5862 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5841 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5856 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5858 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5842 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5848 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5829 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5843 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5862 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5857 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5849 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5853 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5852 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5862 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5855 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5843 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 151us/step - loss: 0.5866 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5866 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5855 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5851 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5838 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5839 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5847 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5846 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5848 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5849 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5854 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5857 - acc: 0.7327\n",
            "2348/2348 [==============================] - 1s 246us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 355us/step - loss: 0.5775 - acc: 0.7340\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5741 - acc: 0.7362\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5755 - acc: 0.7376\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5753 - acc: 0.7370\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5750 - acc: 0.7370\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 150us/step - loss: 0.5748 - acc: 0.7370\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5749 - acc: 0.7370\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5754 - acc: 0.7372\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5804 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5792 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5796 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5806 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 152us/step - loss: 0.5792 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 152us/step - loss: 0.5796 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5790 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5808 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5783 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5794 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5807 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5809 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5797 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5791 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5796 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5797 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5802 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5787 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 151us/step - loss: 0.5800 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 153us/step - loss: 0.5801 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5792 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5793 - acc: 0.7379\n",
            "2347/2347 [==============================] - 1s 262us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 379us/step - loss: 0.5871 - acc: 0.7323\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5895 - acc: 0.7331\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5863 - acc: 0.7333\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5850 - acc: 0.7335\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5879 - acc: 0.7333\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5867 - acc: 0.7333\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5901 - acc: 0.7333\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5894 - acc: 0.7333\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5884 - acc: 0.7333\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5886 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5894 - acc: 0.7333\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5889 - acc: 0.7333\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5900 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5877 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5891 - acc: 0.7333\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5885 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5889 - acc: 0.7333\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5885 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5900 - acc: 0.7321\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5890 - acc: 0.7333\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5893 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5879 - acc: 0.7321\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5885 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5871 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5873 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5870 - acc: 0.7333\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5880 - acc: 0.7333\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5886 - acc: 0.7333\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5868 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5885 - acc: 0.7333\n",
            "2348/2348 [==============================] - 1s 275us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 386us/step - loss: 0.5869 - acc: 0.7321\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5809 - acc: 0.7321\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5808 - acc: 0.7318\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5809 - acc: 0.7314\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5811 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5812 - acc: 0.7310\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5815 - acc: 0.7318\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5816 - acc: 0.7299\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5808 - acc: 0.7295\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5810 - acc: 0.7318\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5808 - acc: 0.7314\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5808 - acc: 0.7304\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5818 - acc: 0.7312\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5796 - acc: 0.7323\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5812 - acc: 0.7318\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5814 - acc: 0.7314\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5811 - acc: 0.7301\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5800 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5807 - acc: 0.7306\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5805 - acc: 0.7306\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5818 - acc: 0.7340\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5825 - acc: 0.7321\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5818 - acc: 0.7301\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5812 - acc: 0.7310\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5800 - acc: 0.7325\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5796 - acc: 0.7321\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5759 - acc: 0.7331\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5767 - acc: 0.7323\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5765 - acc: 0.7308\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5776 - acc: 0.7297\n",
            "2348/2348 [==============================] - 1s 282us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 391us/step - loss: 0.5783 - acc: 0.7381\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5781 - acc: 0.7374\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5822 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 154us/step - loss: 0.5826 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5826 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5833 - acc: 0.7379\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5813 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5793 - acc: 0.7376\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5827 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5807 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5813 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5798 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5807 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5835 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5820 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5813 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5818 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5813 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5821 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5821 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5822 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5814 - acc: 0.7379\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 156us/step - loss: 0.5830 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5820 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5804 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5809 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5842 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5818 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5817 - acc: 0.7379\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5817 - acc: 0.7379\n",
            "2347/2347 [==============================] - 1s 289us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 400us/step - loss: 0.5930 - acc: 0.7327\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5900 - acc: 0.7323\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5901 - acc: 0.7333\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5872 - acc: 0.7333\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5894 - acc: 0.7333\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5881 - acc: 0.7333\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5899 - acc: 0.7333\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5892 - acc: 0.7333\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5891 - acc: 0.7333\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5896 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5878 - acc: 0.7333\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5880 - acc: 0.7333\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5881 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5900 - acc: 0.7333\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5888 - acc: 0.7333\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5894 - acc: 0.7333\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5906 - acc: 0.7321\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5890 - acc: 0.7333\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5907 - acc: 0.7312\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5894 - acc: 0.7316\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5881 - acc: 0.7333\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5906 - acc: 0.7333\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 175us/step - loss: 0.5864 - acc: 0.7333\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 174us/step - loss: 0.5891 - acc: 0.7333\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5881 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5890 - acc: 0.7333\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5876 - acc: 0.7333\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5882 - acc: 0.7333\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5888 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5894 - acc: 0.7333\n",
            "2348/2348 [==============================] - 1s 293us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 411us/step - loss: 0.5870 - acc: 0.7306\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5856 - acc: 0.7329\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5872 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5882 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5862 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5873 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5862 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5870 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5882 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5889 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5869 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5866 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 157us/step - loss: 0.5867 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5892 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5865 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5877 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 152us/step - loss: 0.5898 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5850 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5849 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5869 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 154us/step - loss: 0.5864 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5869 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 153us/step - loss: 0.5857 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5867 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5857 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 155us/step - loss: 0.5846 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5850 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5860 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 156us/step - loss: 0.5866 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 158us/step - loss: 0.5843 - acc: 0.7327\n",
            "2348/2348 [==============================] - 1s 300us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 421us/step - loss: 0.5838 - acc: 0.7368\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 157us/step - loss: 0.5844 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5844 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 155us/step - loss: 0.5876 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5869 - acc: 0.7366\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5852 - acc: 0.7357\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5881 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5853 - acc: 0.7379\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5879 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5887 - acc: 0.7366\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5872 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5854 - acc: 0.7379\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5866 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5889 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5866 - acc: 0.7362\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5873 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 158us/step - loss: 0.5886 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5855 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 160us/step - loss: 0.5856 - acc: 0.7379\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5870 - acc: 0.7379\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5878 - acc: 0.7379\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5879 - acc: 0.7366\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5853 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5865 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 159us/step - loss: 0.5848 - acc: 0.7379\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5860 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5868 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5870 - acc: 0.7379\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5866 - acc: 0.7374\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5873 - acc: 0.7379\n",
            "2347/2347 [==============================] - 1s 303us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 416us/step - loss: 0.5903 - acc: 0.7323\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5840 - acc: 0.7318\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5832 - acc: 0.7325\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5868 - acc: 0.7331\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5838 - acc: 0.7306\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5835 - acc: 0.7308\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5863 - acc: 0.7304\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5850 - acc: 0.7310\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5856 - acc: 0.7316\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5840 - acc: 0.7325\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5833 - acc: 0.7284\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5863 - acc: 0.7321\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 160us/step - loss: 0.5851 - acc: 0.7310\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5871 - acc: 0.7310\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5841 - acc: 0.7316\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5837 - acc: 0.7323\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5843 - acc: 0.7338\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5852 - acc: 0.7314\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5864 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5836 - acc: 0.7308\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 159us/step - loss: 0.5804 - acc: 0.7321\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5849 - acc: 0.7306\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5868 - acc: 0.7340\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5835 - acc: 0.7325\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5855 - acc: 0.7331\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5851 - acc: 0.7318\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5846 - acc: 0.7335\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5867 - acc: 0.7314\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5849 - acc: 0.7301\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5881 - acc: 0.7310\n",
            "2348/2348 [==============================] - 1s 319us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 440us/step - loss: 0.5866 - acc: 0.7312\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5845 - acc: 0.7325\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5846 - acc: 0.7327\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5845 - acc: 0.7327\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5857 - acc: 0.7327\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5836 - acc: 0.7327\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5840 - acc: 0.7327\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5842 - acc: 0.7327\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5843 - acc: 0.7327\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5871 - acc: 0.7327\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5873 - acc: 0.7327\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5863 - acc: 0.7327\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5880 - acc: 0.7327\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5857 - acc: 0.7327\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5887 - acc: 0.7327\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5869 - acc: 0.7327\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5870 - acc: 0.7327\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5886 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5863 - acc: 0.7327\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5861 - acc: 0.7327\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5865 - acc: 0.7327\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5878 - acc: 0.7327\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5887 - acc: 0.7327\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5883 - acc: 0.7327\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5872 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5863 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5887 - acc: 0.7318\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 161us/step - loss: 0.5883 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5874 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5881 - acc: 0.7327\n",
            "2348/2348 [==============================] - 1s 319us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 444us/step - loss: 0.5892 - acc: 0.7364\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 161us/step - loss: 0.5870 - acc: 0.7379\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5841 - acc: 0.7379\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5899 - acc: 0.7366\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5854 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5857 - acc: 0.7353\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5873 - acc: 0.7353\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5898 - acc: 0.7357\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5844 - acc: 0.7353\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5892 - acc: 0.7379\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5903 - acc: 0.7379\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5873 - acc: 0.7374\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5909 - acc: 0.7379\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5891 - acc: 0.7357\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5880 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 162us/step - loss: 0.5896 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5871 - acc: 0.7357\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5898 - acc: 0.7340\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5871 - acc: 0.7366\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5886 - acc: 0.7366\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5886 - acc: 0.7374\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5864 - acc: 0.7353\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 163us/step - loss: 0.5884 - acc: 0.7379\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5874 - acc: 0.7328\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5916 - acc: 0.7370\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 163us/step - loss: 0.5911 - acc: 0.7374\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5876 - acc: 0.7349\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5884 - acc: 0.7336\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5890 - acc: 0.7370\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5905 - acc: 0.7366\n",
            "2347/2347 [==============================] - 1s 330us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 457us/step - loss: 0.5919 - acc: 0.7304\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5921 - acc: 0.7325\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5901 - acc: 0.7312\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5889 - acc: 0.7295\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5915 - acc: 0.7316\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5899 - acc: 0.7299\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5962 - acc: 0.7304\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5936 - acc: 0.7318\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 162us/step - loss: 0.5960 - acc: 0.7316\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5942 - acc: 0.7333\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5924 - acc: 0.7321\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5942 - acc: 0.7329\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5955 - acc: 0.7333\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5952 - acc: 0.7282\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5931 - acc: 0.7325\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5942 - acc: 0.7321\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5948 - acc: 0.7312\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5914 - acc: 0.7321\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5946 - acc: 0.7321\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5946 - acc: 0.7325\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5955 - acc: 0.7278\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5930 - acc: 0.7304\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5931 - acc: 0.7286\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5974 - acc: 0.7295\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5938 - acc: 0.7333\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5948 - acc: 0.7316\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5973 - acc: 0.7312\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5936 - acc: 0.7304\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5943 - acc: 0.7333\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5932 - acc: 0.7325\n",
            "2348/2348 [==============================] - 1s 340us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 463us/step - loss: 0.5962 - acc: 0.7306\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5955 - acc: 0.7297\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5984 - acc: 0.7280\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5960 - acc: 0.7284\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5935 - acc: 0.7289\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5977 - acc: 0.7301\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5973 - acc: 0.7276\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.6006 - acc: 0.7265\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5941 - acc: 0.7293\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5937 - acc: 0.7282\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5935 - acc: 0.7272\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5907 - acc: 0.7310\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5924 - acc: 0.7280\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5943 - acc: 0.7308\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 164us/step - loss: 0.5989 - acc: 0.7272\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5947 - acc: 0.7310\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5885 - acc: 0.7261\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5859 - acc: 0.7278\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5883 - acc: 0.7282\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5883 - acc: 0.7297\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5877 - acc: 0.7284\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5891 - acc: 0.7316\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5892 - acc: 0.7310\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5927 - acc: 0.7297\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5965 - acc: 0.7327\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5929 - acc: 0.7293\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 163us/step - loss: 0.5941 - acc: 0.7327\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5924 - acc: 0.7327\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 165us/step - loss: 0.5949 - acc: 0.7327\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 166us/step - loss: 0.5965 - acc: 0.7301\n",
            "2348/2348 [==============================] - 1s 354us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 476us/step - loss: 0.5902 - acc: 0.7362\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5907 - acc: 0.7370\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5874 - acc: 0.7364\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5893 - acc: 0.7379\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 164us/step - loss: 0.5906 - acc: 0.7379\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5897 - acc: 0.7366\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5887 - acc: 0.7366\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5896 - acc: 0.7357\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5913 - acc: 0.7366\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5889 - acc: 0.7353\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5879 - acc: 0.7370\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5899 - acc: 0.7349\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5903 - acc: 0.7370\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5911 - acc: 0.7379\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5908 - acc: 0.7379\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5894 - acc: 0.7379\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5879 - acc: 0.7370\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5881 - acc: 0.7357\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5887 - acc: 0.7353\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5874 - acc: 0.7370\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5894 - acc: 0.7336\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5918 - acc: 0.7366\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5894 - acc: 0.7353\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5848 - acc: 0.7362\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5893 - acc: 0.7362\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5891 - acc: 0.7379\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5884 - acc: 0.7353\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5901 - acc: 0.7366\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5898 - acc: 0.7353\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5868 - acc: 0.7370\n",
            "2347/2347 [==============================] - 1s 364us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 485us/step - loss: 0.5946 - acc: 0.7295\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5932 - acc: 0.7284\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5941 - acc: 0.7316\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5956 - acc: 0.7295\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 0.5967 - acc: 0.7269\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5952 - acc: 0.7278\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5930 - acc: 0.7299\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5942 - acc: 0.7282\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5969 - acc: 0.7308\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5990 - acc: 0.7291\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5966 - acc: 0.7295\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 174us/step - loss: 0.5954 - acc: 0.7265\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5966 - acc: 0.7312\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5964 - acc: 0.7312\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5976 - acc: 0.7312\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5943 - acc: 0.7276\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5930 - acc: 0.7323\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 177us/step - loss: 0.5893 - acc: 0.7259\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5960 - acc: 0.7321\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 167us/step - loss: 0.5958 - acc: 0.7278\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5979 - acc: 0.7286\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 176us/step - loss: 0.5972 - acc: 0.7299\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 168us/step - loss: 0.5989 - acc: 0.7291\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 0.5987 - acc: 0.7308\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 0.5981 - acc: 0.7308\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5959 - acc: 0.7257\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5989 - acc: 0.7321\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5977 - acc: 0.7291\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5978 - acc: 0.7295\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5961 - acc: 0.7295\n",
            "2348/2348 [==============================] - 1s 368us/step\n",
            "Epoch 1/30\n",
            "4695/4695 [==============================] - 2s 491us/step - loss: 0.5918 - acc: 0.7299\n",
            "Epoch 2/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5948 - acc: 0.7301\n",
            "Epoch 3/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5955 - acc: 0.7295\n",
            "Epoch 4/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5949 - acc: 0.7301\n",
            "Epoch 5/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5962 - acc: 0.7301\n",
            "Epoch 6/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5968 - acc: 0.7314\n",
            "Epoch 7/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5977 - acc: 0.7246\n",
            "Epoch 8/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5992 - acc: 0.7263\n",
            "Epoch 9/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.6026 - acc: 0.7306\n",
            "Epoch 10/30\n",
            "4695/4695 [==============================] - 1s 175us/step - loss: 0.5978 - acc: 0.7297\n",
            "Epoch 11/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5955 - acc: 0.7314\n",
            "Epoch 12/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5964 - acc: 0.7297\n",
            "Epoch 13/30\n",
            "4695/4695 [==============================] - 1s 175us/step - loss: 0.5970 - acc: 0.7310\n",
            "Epoch 14/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5962 - acc: 0.7318\n",
            "Epoch 15/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5967 - acc: 0.7301\n",
            "Epoch 16/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 0.5958 - acc: 0.7301\n",
            "Epoch 17/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5973 - acc: 0.7276\n",
            "Epoch 18/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5964 - acc: 0.7327\n",
            "Epoch 19/30\n",
            "4695/4695 [==============================] - 1s 184us/step - loss: 0.5977 - acc: 0.7297\n",
            "Epoch 20/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5959 - acc: 0.7297\n",
            "Epoch 21/30\n",
            "4695/4695 [==============================] - 1s 187us/step - loss: 0.5955 - acc: 0.7297\n",
            "Epoch 22/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.5973 - acc: 0.7306\n",
            "Epoch 23/30\n",
            "4695/4695 [==============================] - 1s 172us/step - loss: 0.6000 - acc: 0.7263\n",
            "Epoch 24/30\n",
            "4695/4695 [==============================] - 1s 170us/step - loss: 0.5955 - acc: 0.7301\n",
            "Epoch 25/30\n",
            "4695/4695 [==============================] - 1s 173us/step - loss: 0.5939 - acc: 0.7289\n",
            "Epoch 26/30\n",
            "4695/4695 [==============================] - 1s 176us/step - loss: 0.5958 - acc: 0.7327\n",
            "Epoch 27/30\n",
            "4695/4695 [==============================] - 1s 171us/step - loss: 0.5975 - acc: 0.7314\n",
            "Epoch 28/30\n",
            "4695/4695 [==============================] - 1s 174us/step - loss: 0.6004 - acc: 0.7310\n",
            "Epoch 29/30\n",
            "4695/4695 [==============================] - 1s 174us/step - loss: 0.6001 - acc: 0.7293\n",
            "Epoch 30/30\n",
            "4695/4695 [==============================] - 1s 169us/step - loss: 0.5951 - acc: 0.7318\n",
            "2348/2348 [==============================] - 1s 370us/step\n",
            "Epoch 1/30\n",
            "4696/4696 [==============================] - 2s 500us/step - loss: 0.5878 - acc: 0.7355\n",
            "Epoch 2/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5884 - acc: 0.7353\n",
            "Epoch 3/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5878 - acc: 0.7362\n",
            "Epoch 4/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5879 - acc: 0.7362\n",
            "Epoch 5/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5912 - acc: 0.7362\n",
            "Epoch 6/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5890 - acc: 0.7340\n",
            "Epoch 7/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5895 - acc: 0.7379\n",
            "Epoch 8/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5866 - acc: 0.7349\n",
            "Epoch 9/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5904 - acc: 0.7379\n",
            "Epoch 10/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5897 - acc: 0.7332\n",
            "Epoch 11/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5891 - acc: 0.7349\n",
            "Epoch 12/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5875 - acc: 0.7370\n",
            "Epoch 13/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5884 - acc: 0.7374\n",
            "Epoch 14/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5908 - acc: 0.7328\n",
            "Epoch 15/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5884 - acc: 0.7362\n",
            "Epoch 16/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5888 - acc: 0.7349\n",
            "Epoch 17/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5880 - acc: 0.7379\n",
            "Epoch 18/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5893 - acc: 0.7379\n",
            "Epoch 19/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5882 - acc: 0.7370\n",
            "Epoch 20/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5901 - acc: 0.7357\n",
            "Epoch 21/30\n",
            "4696/4696 [==============================] - 1s 165us/step - loss: 0.5875 - acc: 0.7340\n",
            "Epoch 22/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5905 - acc: 0.7364\n",
            "Epoch 23/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5900 - acc: 0.7362\n",
            "Epoch 24/30\n",
            "4696/4696 [==============================] - 1s 167us/step - loss: 0.5910 - acc: 0.7379\n",
            "Epoch 25/30\n",
            "4696/4696 [==============================] - 1s 168us/step - loss: 0.5910 - acc: 0.7366\n",
            "Epoch 26/30\n",
            "4696/4696 [==============================] - 1s 166us/step - loss: 0.5920 - acc: 0.7357\n",
            "Epoch 27/30\n",
            "4696/4696 [==============================] - 1s 169us/step - loss: 0.5916 - acc: 0.7379\n",
            "Epoch 28/30\n",
            "4696/4696 [==============================] - 1s 172us/step - loss: 0.5925 - acc: 0.7336\n",
            "Epoch 29/30\n",
            "4696/4696 [==============================] - 1s 171us/step - loss: 0.5910 - acc: 0.7370\n",
            "Epoch 30/30\n",
            "4696/4696 [==============================] - 1s 170us/step - loss: 0.5905 - acc: 0.7357\n",
            "2347/2347 [==============================] - 1s 377us/step\n",
            "Epoch 1/30\n",
            "7043/7043 [==============================] - 3s 401us/step - loss: 0.6384 - acc: 0.6604\n",
            "Epoch 2/30\n",
            "7043/7043 [==============================] - 1s 172us/step - loss: 0.5796 - acc: 0.7325\n",
            "Epoch 3/30\n",
            "7043/7043 [==============================] - 1s 171us/step - loss: 0.5778 - acc: 0.7334\n",
            "Epoch 4/30\n",
            "7043/7043 [==============================] - 1s 173us/step - loss: 0.5775 - acc: 0.7335\n",
            "Epoch 5/30\n",
            "7043/7043 [==============================] - 1s 175us/step - loss: 0.5772 - acc: 0.7336\n",
            "Epoch 6/30\n",
            "7043/7043 [==============================] - 1s 173us/step - loss: 0.5769 - acc: 0.7338\n",
            "Epoch 7/30\n",
            "7043/7043 [==============================] - 1s 172us/step - loss: 0.5768 - acc: 0.7339\n",
            "Epoch 8/30\n",
            "7043/7043 [==============================] - 1s 176us/step - loss: 0.5766 - acc: 0.7339\n",
            "Epoch 9/30\n",
            "7043/7043 [==============================] - 1s 182us/step - loss: 0.5765 - acc: 0.7339\n",
            "Epoch 10/30\n",
            "7043/7043 [==============================] - 1s 184us/step - loss: 0.5761 - acc: 0.7339\n",
            "Epoch 11/30\n",
            "7043/7043 [==============================] - 1s 187us/step - loss: 0.5758 - acc: 0.7339\n",
            "Epoch 12/30\n",
            "7043/7043 [==============================] - 1s 185us/step - loss: 0.5761 - acc: 0.7339\n",
            "Epoch 13/30\n",
            "7043/7043 [==============================] - 1s 185us/step - loss: 0.5758 - acc: 0.7339\n",
            "Epoch 14/30\n",
            "7043/7043 [==============================] - 1s 180us/step - loss: 0.5743 - acc: 0.7339\n",
            "Epoch 15/30\n",
            "7043/7043 [==============================] - 1s 184us/step - loss: 0.5737 - acc: 0.7339\n",
            "Epoch 16/30\n",
            "7043/7043 [==============================] - 1s 188us/step - loss: 0.5734 - acc: 0.7339\n",
            "Epoch 17/30\n",
            "7043/7043 [==============================] - 1s 179us/step - loss: 0.5730 - acc: 0.7341\n",
            "Epoch 18/30\n",
            "7043/7043 [==============================] - 1s 175us/step - loss: 0.5724 - acc: 0.7341\n",
            "Epoch 19/30\n",
            "7043/7043 [==============================] - 1s 173us/step - loss: 0.5720 - acc: 0.7339\n",
            "Epoch 20/30\n",
            "7043/7043 [==============================] - 1s 186us/step - loss: 0.5756 - acc: 0.7342\n",
            "Epoch 21/30\n",
            "7043/7043 [==============================] - 1s 184us/step - loss: 0.5758 - acc: 0.7343\n",
            "Epoch 22/30\n",
            "7043/7043 [==============================] - 1s 184us/step - loss: 0.5756 - acc: 0.7345\n",
            "Epoch 23/30\n",
            "7043/7043 [==============================] - 1s 179us/step - loss: 0.5756 - acc: 0.7345\n",
            "Epoch 24/30\n",
            "7043/7043 [==============================] - 1s 186us/step - loss: 0.5756 - acc: 0.7345\n",
            "Epoch 25/30\n",
            "7043/7043 [==============================] - 1s 180us/step - loss: 0.5757 - acc: 0.7345\n",
            "Epoch 26/30\n",
            "7043/7043 [==============================] - 1s 185us/step - loss: 0.5758 - acc: 0.7345\n",
            "Epoch 27/30\n",
            "7043/7043 [==============================] - 1s 186us/step - loss: 0.5758 - acc: 0.7346\n",
            "Epoch 28/30\n",
            "7043/7043 [==============================] - 1s 183us/step - loss: 0.5757 - acc: 0.7345\n",
            "Epoch 29/30\n",
            "7043/7043 [==============================] - 1s 179us/step - loss: 0.5755 - acc: 0.7346\n",
            "Epoch 30/30\n",
            "7043/7043 [==============================] - 1s 181us/step - loss: 0.5754 - acc: 0.7346\n",
            "Best: 0.7349140991139578 using {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "Means: 0.7344881442651717, Stdev: 0.004524941307339734 with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "Means: 0.7349140991139578, Stdev: 0.00477546457187304 with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "Means: 0.7347721141643624, Stdev: 0.0046848462227997495 with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
            "Means: 0.7344881442651717, Stdev: 0.004524941307339734 with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "Means: 0.7306545506260975, Stdev: 0.004690215710855591 with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
            "Means: 0.7332102797188137, Stdev: 0.004223596006489424 with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
            "Means: 0.7346301292147671, Stdev: 0.004601209418964332 with: {'learn_rate': 0.2, 'momentum': 0.4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfZRtJ7MCN3x",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}